
# 论文阅读笔记

# PAN: Towards Fast Action Recognition via Learning Persistence of Appearance

## Abstract

- 有效地建模视频中的动态运动信息是动作识别任务的关键。大多数最先进的方法在很大程度上依赖于稠密的光流来表示运动。
- 虽然将光流与RGB帧相结合作为输入可以取得很好的识别性能，但是光流提取非常耗时

- 在本文中，我们通过提高对光流的依赖来阐明快速动作识别。
- 我们的动机在于观察到运动边界的微小位移是区分动作的最关键的成分，因此我们设计了一个新的运动线索，称为外观的持久性(PA)。

- 与光流相比，我们的PA更专注于提取边界处的运动信息。
- 它只通过在特征空间中逐像素累积差异而不是对所有可能的运动向量进行穷举的逐块搜索，从而提高效率。

- 在运动建模速度方面，我们的PA比传统光流快1000多倍(8196fps vs 8fps)。

- 为了进一步将PA中的短期动态聚合为长期动态，我们还设计了一种称为变时间尺度聚合池(VAP)的全局时间融合策略，该策略可以自适应地建模跨不同时间尺度的长期时间关系。

- 最后，我们将所提出的PA和VAP结合起来，形成了具有较强时态建模能力的统一框架——持久外观网络(PAN)。

- 在六个具有挑战性的动作识别基准上进行的广泛实验验证了我们的PAN在较低的FLOPs情况下 优于目前最先进的方法。

- Codes and models are available at: https://github.com/zhang-can/PAN-PyTorch.



## VI. Conclusion

- 在本文中，我们通过提高对光流的依赖来阐明快速动作识别。
- 我们设计了一种简洁的运动提示，称为外观持久性(PA)，直接从RGB帧中捕获运动信息。
- 与光流法相比，PA方法更多得聚焦于 对运动边界的小规模位移进行建模，而且通过简单地计算特征空间中相邻两帧之间的像素差，可以提高算法的效率。

- 该方法的运动建模速度比传统的光流法快1000倍。

- 为了进一步将PA中的短期动态聚合为长期动态，我们还提出了一种时间融合策略，名为可变时间尺度聚合池(VAP)， 它使网络能够捕获远距离的各种尺度的相互依赖关系。

- 最后将所提出的PA和VAP结合在一起，形成了一个统一的框架 称为持续出现的网络(PAN)。

- 实验结果表明，他具有最优的性能，最重要的是，在强有力的动作提示PA的作用下，它显著地加速了动作识别的推理过程。